# Bdot
## Fast Dot Products on Pretty Big Data

[![Build Status](https://travis-ci.org/pinleague/bdot.svg)](https://travis-ci.org/pinleague/bdot)

Bdot makes your ram bigger on the inside. Since it's based on [Bcolz](https://github.com/Blosc/bcolz/)
you also get (mostly) transparant compressed disk based storage for free.

![Bigger on the Inside](https://31.media.tumblr.com/dcd82ee9cc541ef6774572e9110de082/tumblr_inline_n3eq30Vjhh1rnbe7i.gif)

Supports `matrix . vector` and `matrix . matrix` for most common numpy numeric data types (`numpy.int64`, `numpy.int32`, `numpy.float64`, `numpy.float32`)

## Install
```bash
pip install bdot
```

or build from source (requires bcolz >= 0.9.0)

```bash
python setup.py build_ext --inplace
python setup.py install
```

## Usage

### Matrix . Vector

Multiply a matrix (stored in a `carray`) with a vector (`numpy.ndarray`)

```python
import bdot
import bcolz
import numpy as np

matrix = np.random.random_integers(0, 12000, size=(300000, 100))
bcarray = bdot.carray(matrix, chunklen=2**13, cparams=bcolz.cparams(clevel=2))

v = bcarray[0]

result = bcarray.dot(v)
expected = matrix.dot(v)

# should return True
(expected == result).all()

```

### Matrix . Matrix

Multiply a matrix (stored in a `carray`) with the transpose of another matrix (also in a `carray`).

```python

import bdot
import bcolz
import numpy as np

matrix = np.random.random_integers(0, 120, size=(1000, 100))
bcarray1 = bdot.carray(matrix, chunklen=2**9, cparams=bcolz.cparams(clevel=2))
bcarray2 = bdot.carray(matrix, chunklen=2**9, cparams=bcolz.cparams(clevel=2))

# calculates bcarray1 . bcarray2.T (transpose)
result = bcarray1.dot(bcarray2)
expected = matrix.dot(matrix.T)

# should return True
(expected == result).all()

```

## Simple Benchmarks

Benchmarks were done on data structures generated by the above code, are very informal, and vary a bit across data sets.

### Space

* `numpy` ~229MB
* `bdot` ~64MB

compression ratio: 3.55 
(this tells you what multiple of the RAM in your machine you can operate with)


compression ratio on real world (non-random) data tends to be better (~5x)

### Time
`numpy`
```python
%timeit -n30 -r2 matrix.dot(v)

30 loops, best of 2: 33 ms per loop
```
`bdot`
```python
%timeit -n30 -r2 bcarray.dot(v)

30 loops, best of 2: 48.2 ms per loop
```


## Goals

This project has three goals, each slightly more fantastic than the last:

1. Allow computation on (compressed) data which is (~5-10x) larger than RAM at approximately the same speed as `numpy.dot`


2. Allow computation on (slightly compressed) data at speeds that improve on `numpy.dot`


3. Allow computation on (compressed) data which resides on disk at some sizable percentage (~50-30%) of the speed of `numpy.dot`


So far, the first goal has been met.


## Acknowledgements

This library wouldn't be possible without all the talented people who worked hard to create [Bcolz](https://github.com/Blosc/bcolz/) (and the libraries on which it's based). Initial code was also heavily influenced by [Bquery](https://github.com/visualfabriq/bquery).
